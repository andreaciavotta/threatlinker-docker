#!/bin/bash

if [ -f "/usr/local/cuda/version.txt" ]; then
    echo "‚úÖ CUDA √® gi√† installata, salto l'installazione."
    exit 0
fi

echo "üîç Controllo se CUDA √® disponibile..."

# 1Ô∏è‚É£ Trova la versione corretta di CUDA
if command -v nvcc &> /dev/null; then
    CUDA_VERSION=$(nvcc --version | grep "release" | awk '{print $6}' | cut -c2-)
elif [ -f "/usr/local/cuda/version.txt" ]; then
    CUDA_VERSION=$(cat /usr/local/cuda/version.txt | grep -oE '[0-9]+\.[0-9]+')
elif command -v nvidia-smi &> /dev/null; then
    CUDA_VERSION=$(nvidia-smi | grep "CUDA Version" | awk '{print $9}')
else
    CUDA_VERSION="cpu"
fi

# Estrai solo i primi due numeri della versione (es. 12.2 -> 12.2)
CUDA_VERSION_SHORT=$(echo $CUDA_VERSION | cut -d. -f1,2)

# Mappiamo la versione CUDA con quella supportata da PyTorch
case $CUDA_VERSION_SHORT in
    "12.2") PYTORCH_CUDA_VERSION="cu121" ;;  # Non esiste cu122, quindi usiamo cu121
    "12.3"|"12.4") PYTORCH_CUDA_VERSION="cu123" ;;  # Se maggiore di 12.3, usiamo cu123
    "12.1") PYTORCH_CUDA_VERSION="cu121" ;;  # CUDA 12.1 esiste direttamente
    "11.8") PYTORCH_CUDA_VERSION="cu118" ;;  # CUDA 11.8 esiste direttamente
    "11.7") PYTORCH_CUDA_VERSION="cu117" ;;  # CUDA 11.7 esiste direttamente
    *) PYTORCH_CUDA_VERSION="cpu" ;;  # Se non √® una di queste, usa CPU
esac

echo "‚úÖ CUDA trovata: Versione $CUDA_VERSION_SHORT -> Mappata a PyTorch: $PYTORCH_CUDA_VERSION"

# 3Ô∏è‚É£ Installa PyTorch per CUDA corretta o CPU
echo "üñ•Ô∏è Verifica dell'installazione di PyTorch..."

if python3 -c "import torch" &> /dev/null; then
    echo "‚úÖ PyTorch √® gi√† installato, nessuna reinstallazione necessaria."
else
    if [ "$PYTORCH_CUDA_VERSION" != "cpu" ]; then
        echo "üñ•Ô∏è Installazione PyTorch per CUDA $CUDA_VERSION_SHORT (Indice: $PYTORCH_CUDA_VERSION)..."
        
        # Controlliamo se l'URL della versione esiste prima di installare
        if curl --output /dev/null --silent --head --fail "https://download.pytorch.org/whl/$PYTORCH_CUDA_VERSION/"; then
            if pip install --no-cache-dir torch --index-url "https://download.pytorch.org/whl/$PYTORCH_CUDA_VERSION"; then
                echo "‚úÖ PyTorch installato correttamente con supporto CUDA $CUDA_VERSION_SHORT!"
            else
                echo "‚ùå ERRORE: Installazione di PyTorch per CUDA fallita!"
                exit 1
            fi
        else
            echo "‚ùå ERRORE: L'index-url per PyTorch CUDA $PYTORCH_CUDA_VERSION non esiste. Installazione fallback su CPU."
            PYTORCH_CUDA_VERSION="cpu"
        fi
    fi

    # Se CUDA non √® disponibile o se l'installazione CUDA √® fallita, installiamo PyTorch per CPU
    if [ "$PYTORCH_CUDA_VERSION" = "cpu" ]; then
        echo "‚ö†Ô∏è Nessun supporto CUDA trovato. Installazione PyTorch per CPU..."
        if pip install --no-cache-dir torch --index-url "https://download.pytorch.org/whl/cpu"; then
            echo "‚úÖ PyTorch per CPU installato correttamente!"
        else
            echo "‚ùå ERRORE: Installazione di PyTorch per CPU fallita!"
            exit 1
        fi
    fi
fi

# 4Ô∏è‚É£ **Crea il file flag per indicare che CUDA √® stata installata**
echo "$CUDA_VERSION_SHORT" > /usr/local/cuda/version.txt

# 4Ô∏è‚É£ **Test finale: verifica se PyTorch riconosce CUDA**
echo "üîç Verifica se PyTorch riconosce CUDA..."
python3 -c "import torch; cuda_available = torch.cuda.is_available(); gpu_name = torch.cuda.get_device_name(0) if cuda_available else 'Nessuna GPU trovata'; print(f'‚úÖ torch.cuda.is_available(): {cuda_available}'); print(f'üñ•Ô∏è GPU: {gpu_name}')"

if [ $? -ne 0 ]; then
    echo "‚ùå ERRORE: PyTorch non riconosce CUDA!"
    exit 1
fi

echo "‚úÖ Setup completato con successo!"